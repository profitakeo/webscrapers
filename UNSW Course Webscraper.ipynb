{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping UNSW Courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup # BeautifulSoup is a Python library for pulling data out of HTML and XML files\n",
    "import urllib.request # Python module for fetching URLs\n",
    "from IPython.display import HTML\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   Class Search by Teaching Period\n",
      "  </title>\n",
      "  <link href=\"../layout/2020/\n"
     ]
    }
   ],
   "source": [
    "# Open URL\n",
    "html = urllib.request.urlopen('http://timetable.unsw.edu.au/2020/subjectSearch.html').read()\n",
    "\n",
    "# Parse HTML data\n",
    "soup = BeautifulSoup(html, \"lxml\")\n",
    "\n",
    "# Prints first 100 characters\n",
    "print(soup.prettify()[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to access different links\n",
    "# for different subject area pages\n",
    "endLinks = []\n",
    "\n",
    "# Filter through HTML <td>, <tr> and <a> tags, and create\n",
    "# a list of partial links for all subject areas\n",
    "for list_td in soup.find_all('td', attrs={'class':\"formBody\"}):\n",
    "    for list_tr in list_td.find_all('tr', attrs={'class':\"rowLowlight\"}):\n",
    "        for list_a in list_tr.find_all('a'):\n",
    "            endLinks.append(list_a.get('href'))\n",
    "    for list_tr in list_td.find_all('tr', attrs={'class':\"rowHighlight\"}):\n",
    "        for list_a in list_tr.find_all('a'):\n",
    "            endLinks.append(list_a.get('href'))\n",
    "\n",
    "# Convert list to DF\n",
    "endLinks = pd.DataFrame(endLinks)\n",
    "\n",
    "# Remove duplicates\n",
    "endLinks = endLinks.drop_duplicates()\n",
    "\n",
    "# Sort DF in alphanumeric order by column '0'\n",
    "endLinks.columns = ['0']\n",
    "endLinks = endLinks.sort_values(by='0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Course Code                                 Course Name UoC  \\\n",
      "0       ACCT1501      Accounting and Financial Management 1A   6   \n",
      "1       ACCT1511      Accounting and Financial Management 1B   6   \n",
      "2       ACCT2101                        Industry Placement 1  12   \n",
      "3       ACCT2522                     Management Accounting 1   6   \n",
      "4       ACCT2542  Corporate Financial Reporting and Analysis   6   \n",
      "...          ...                                         ...  ..   \n",
      "4328    ZZSC5806     Regression Analysis for Data Scientists   6   \n",
      "4329    ZZSC5836            Data Mining and Machine Learning   6   \n",
      "4330    ZZSC5855   Multivariate Analysis for Data Scientists   6   \n",
      "4331    ZZSC5905   Statistical Inference for Data Scientists   6   \n",
      "4332    ZZSC9001                 Foundations of Data Science   6   \n",
      "\n",
      "             Subject Area University               Faculty  \\\n",
      "0              Accounting       UNSW  UNSW Business School   \n",
      "1              Accounting       UNSW  UNSW Business School   \n",
      "2              Accounting       UNSW  UNSW Business School   \n",
      "3              Accounting       UNSW  UNSW Business School   \n",
      "4              Accounting       UNSW  UNSW Business School   \n",
      "...                   ...        ...                   ...   \n",
      "4328  Science Accelerated       UNSW    Faculty of Science   \n",
      "4329  Science Accelerated       UNSW    Faculty of Science   \n",
      "4330  Science Accelerated       UNSW    Faculty of Science   \n",
      "4331  Science Accelerated       UNSW    Faculty of Science   \n",
      "4332  Science Accelerated       UNSW    Faculty of Science   \n",
      "\n",
      "                            School  Campus                 Career  \n",
      "0             School of Accounting  Sydney          Undergraduate  \n",
      "1             School of Accounting  Sydney          Undergraduate  \n",
      "2             School of Accounting  Sydney          Undergraduate  \n",
      "3             School of Accounting  Sydney          Undergraduate  \n",
      "4             School of Accounting  Sydney          Undergraduate  \n",
      "...                            ...     ...                    ...  \n",
      "4328  Sch Mathematics & Statistics  Sydney  Postgraduate (Online)  \n",
      "4329  Sch Mathematics & Statistics  Sydney  Postgraduate (Online)  \n",
      "4330  Sch Mathematics & Statistics  Sydney  Postgraduate (Online)  \n",
      "4331  Sch Mathematics & Statistics  Sydney  Postgraduate (Online)  \n",
      "4332  Sch Mathematics & Statistics  Sydney  Postgraduate (Online)  \n",
      "\n",
      "[4333 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create empty lists for features\n",
    "code = [] # Course Code\n",
    "name = [] # Course Name\n",
    "UoC = [] # Units of Credit\n",
    "camp = [] # Campus\n",
    "sub = [] # Subject Area\n",
    "uni = [] # University\n",
    "fac = [] # Faculty\n",
    "sch = [] # School\n",
    "camp = [] # Campus\n",
    "car = [] # Career\n",
    "\n",
    "# Scan website links for all different subject areas\n",
    "for i in range(len(endLinks)):\n",
    "    link = endLinks.iloc[i]\n",
    "    # Convert to string and remove whitespacing\n",
    "    link = link.to_string(index=False).strip()\n",
    "    fullLink = 'http://timetable.unsw.edu.au/2020/' + str(link)\n",
    "    html = urllib.request.urlopen(fullLink).read()\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "    # Create empty lists for preprocessing\n",
    "    infoA = [] # Will contain course Code, Course Title, Units of Credit\n",
    "               # for certain subject area\n",
    "    infoB = [] # Will contain content under <td> tag for certain subject area\n",
    "    endLinksB = [] # Will contain partial links for all subjects\n",
    "    facSubj = [] # Will temporarily contain faculty for each subject\n",
    "    schSubj = [] # Will temporarily contain school for each subject\n",
    "    campSubj = [] # Will temporarily contain campus for each subject\n",
    "    carSubj = [] # Will temporarily contain career for each subject\n",
    "\n",
    "    # Filter through HTML <td>, <tr> and <a> tags, and create\n",
    "    # an 'infoA' and 'infoB' list for a certain subject area\n",
    "    for list_tdBody in soup.find_all('td', attrs={'class':\"formBody\"}):\n",
    "        for list_tr in list_tdBody.find_all('tr', attrs={'class':\"rowLowlight\"}):\n",
    "            for list_a in list_tr.find_all('a'):\n",
    "                endLinksB.append(list_a.get('href'))\n",
    "            for list_tdData in list_tr.find_all('td', attrs={'class':\"data\"}):\n",
    "                infoA.append(list_tdData.text)\n",
    "        for list_tr in list_tdBody.find_all('tr', attrs={'class':\"rowHighlight\"}):\n",
    "            for list_a in list_tr.find_all('a'):\n",
    "                endLinksB.append(list_a.get('href'))\n",
    "            for list_tdData in list_tr.find_all('td', attrs={'class':\"data\"}):\n",
    "                infoA.append(list_tdData.text)\n",
    "        for list_td in list_tdBody.find_all('td'):\n",
    "            infoB.append(list_td.text)\n",
    "            \n",
    "    # Convert list of subject website links to formatted DF \n",
    "    endLinksB = pd.DataFrame(endLinksB)\n",
    "    endLinksB = endLinksB.drop_duplicates()\n",
    "    endLinksB.columns = ['0']\n",
    "    endLinksB = endLinksB.sort_values(by='0')\n",
    "    endLinksB = endLinksB.reset_index(drop=True)\n",
    "    \n",
    "    # For each subject, open website link\n",
    "    for j in range(len(endLinksB)):\n",
    "        linkB = endLinksB.iloc[j]\n",
    "        # Convert to string and remove whitespacing\n",
    "        linkB = linkB.to_string(index=False).strip()\n",
    "        fullLinkB = 'http://timetable.unsw.edu.au/2020/' + str(linkB)\n",
    "        htmlB = urllib.request.urlopen(fullLinkB).read()\n",
    "        soupB = BeautifulSoup(htmlB, 'lxml')\n",
    "        \n",
    "        # Create empty list for preprocessing\n",
    "        infoC = [] # Will contain content under <td> tag for certain subject\n",
    "\n",
    "        # Create list of HTML <td> tags, containing features for a \n",
    "        # certain subject\n",
    "        for list_tdBody in soupB.find_all('td', attrs={'class':\"formBody\"}):\n",
    "            for list_td in list_tdBody.find_all('td'):\n",
    "                infoC.append(list_td.text) \n",
    "\n",
    "        # Extract features for subject\n",
    "        indFac = infoC.index('Faculty ') + 1\n",
    "        faculty = infoC[indFac]\n",
    "        indSch = infoC.index('School ') + 1\n",
    "        school = infoC[indSch]\n",
    "        indCamp = infoC.index('Campus ') + 1\n",
    "        campus = infoC[indCamp]\n",
    "        indCar = infoC.index('Career ') + 1\n",
    "        career = infoC[indCar]\n",
    "        \n",
    "        # Create temporary feature list for all subjects in a subject area\n",
    "        facSubj.append(faculty)\n",
    "        schSubj.append(school)\n",
    "        campSubj.append(campus)\n",
    "        carSubj.append(career)\n",
    "\n",
    "    # Merge permanent and temporary feature lists    \n",
    "    fac = fac + facSubj\n",
    "    sch = sch + schSubj\n",
    "    camp = camp + campSubj\n",
    "    car = car + carSubj\n",
    "        \n",
    "    # Identify subject area\n",
    "    indSubj = infoB.index('Subject Area ') + 1\n",
    "    subjArea = infoB[indSubj]\n",
    "\n",
    "    # Split 'infoA' list into respective feature arrays\n",
    "    for k in range(0,len(infoA),3):\n",
    "        code.append(infoA[k])\n",
    "        name.append(infoA[k+1])\n",
    "        UoC.append(infoA[k+2])\n",
    "        \n",
    "    # Array length of certain subject area\n",
    "    height = int(len(infoA)/3)\n",
    "    \n",
    "    # Populate features with same value\n",
    "    # in a certain subject area\n",
    "    for l in range(height):\n",
    "        sub.append(subjArea)\n",
    "        uni.append('UNSW')\n",
    "        \n",
    "# DF Formatting\n",
    "df = pd.DataFrame({\"Course Code\": code, \"Course Name\": name, \"UoC\": UoC,\\\n",
    "                   \"Subject Area\": sub, \"University\": uni})    \n",
    "df = df.drop_duplicates()\n",
    "df = df.drop_duplicates(subset='Course Code', keep='first')\n",
    "df = df.sort_values(by='Course Code')\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Add additional feature columns\n",
    "df['Faculty']=fac\n",
    "df['School']=sch\n",
    "df['Campus']=camp\n",
    "df['Career']=car\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export DF to Excel\n",
    "with pd.ExcelWriter('UNSW Course List.xlsx') as writer:\n",
    "    df.to_excel(writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting DataFrame to dictionary\n",
    "dictDF = df.to_dict('df')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
